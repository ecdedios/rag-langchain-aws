{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "294ec7e6-326b-4331-b40e-7cab7e46c00a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%sh\n",
    "# pip install sagemaker langchain amazon-textract-caller amazon-textract-textractor sentence-transformers pypdf faiss-cpu -qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68c4a374-67f0-4510-9433-f318e9f0794f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3, json, sagemaker\n",
    "from typing import Dict\n",
    "from langchain import LLMChain\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import SagemakerEndpoint\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07f82b2-2101-4e8b-99ea-d1c7a6baeef8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Deploy LLM on Sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d09dfe37-acd5-48a5-a9a6-1c81d7a1450f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------!"
     ]
    }
   ],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "hub = {\n",
    "\t'HF_MODEL_ID':'mistralai/Mistral-7B-Instruct-v0.1',\n",
    "\t'SM_NUM_GPUS': '1'\n",
    "}\n",
    "\n",
    "huggingface_model = HuggingFaceModel(\n",
    "\timage_uri=get_huggingface_llm_image_uri(\"huggingface\",version=\"1.1.0\"),\n",
    "\tenv=hub,\n",
    "\trole=role \n",
    ")\n",
    "\n",
    "predictor = huggingface_model.deploy(\n",
    "\tinitial_instance_count=1,\n",
    "\tinstance_type=\"ml.g5.2xlarge\",\n",
    "\tcontainer_startup_health_check_timeout=300,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "236a563e-c8c5-4bb0-a350-979e4724988b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'huggingface-pytorch-tgi-inference-2024-01-13-04-46-32-010'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name = predictor.endpoint_name\n",
    "endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f967a0b7-5168-420a-85b4-10588c43297b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Configure LLM in LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d71ff4a-3a8a-4f78-85f5-9301369631b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_kwargs = {\"max_new_tokens\": 512, \"top_p\": 0.8, \"temperature\": 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b485b5fc-65a0-484d-8f34-cea7370693b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: Dict) -> bytes:\n",
    "        input_str = json.dumps(\n",
    "            # Mistral prompt, see https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1\n",
    "            {\"inputs\": f\"<s>[INST] {prompt} [/INST]\", \"parameters\": {**model_kwargs}}\n",
    "        )\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        splits = response_json[0][\"generated_text\"].split(\"[/INST] \")\n",
    "        return splits[1]\n",
    "\n",
    "content_handler = ContentHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28df8d1b-52ac-46b4-9016-57488f8351d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sm_client = boto3.client(\"sagemaker-runtime\") # needed for AWS credentials\n",
    "\n",
    "llm = SagemakerEndpoint(\n",
    "    endpoint_name=endpoint_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    content_handler=content_handler,\n",
    "    client=sm_client,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe279fcb-a403-4b3f-8a66-ecfd5f399ca4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Zero-shot example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50a4f9c8-521c-4e3c-b44f-c01346019fae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "As a helpful human resource specialist, please answer the question.\n",
    "Don't invent facts. If you can't provide a factual answer, say you don't know what the answer is.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(system_prompt + \"{content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "192c9188-35c4-415a-8489-740ec36a4ebe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff1dca50-1b52-497e-ac44-e7dbd6e7956e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"How many years of experience does Ednalyn C. De Dios have?\"\n",
    "\n",
    "query = f\"question: {question}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a380717-1367-4528-bc96-41aa77e35202",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have access to Ednalyn C. De Dios' personal information, so I cannot provide an answer to that question.\n"
     ]
    }
   ],
   "source": [
    "answer = llm_chain.run({query})\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22a63ec-6e01-433f-a0c8-6d87c6090a1b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RAG example with PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dca5cf4-0fa9-4fb9-a171-6cbe7bb4cdda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import AmazonTextractPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26c88887-27c4-4d58-a40d-3bad9ba1c000",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define S3 bucket and prefix for PDF storage\n",
    "\n",
    "bucket = \"rag-langchain-demo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c129ea93-5474-46a2-89d7-ef42010c71b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rag-langchain-demo\n"
     ]
    }
   ],
   "source": [
    "print(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f659dbb2-923b-4c78-97c2-8519b8a2fedf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s3://rag-langchain-demo/1026-ednalyn-de-dios-machine-learning-engineer-data-scientist-manager-readable-2023.pdf',\n",
       " 's3://rag-langchain-demo/1101-ednalyn-de-dios-machine-learning-engineer-data-scientist-manager-readable-2023.pdf',\n",
       " 's3://rag-langchain-demo/925-ednalyn-de-dios-machine-learning-engineer-data-scientist-manager-readable-2023.pdf']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Build list of S3 URIs\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "objs = s3.list_objects_v2(Bucket=bucket)\n",
    "objs = objs['Contents']\n",
    "uris = [f's3://{bucket}/{obj[\"Key\"]}' for obj in objs]\n",
    "uris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a155d793-cb59-49b3-993e-939f6cc18abf",
   "metadata": {
    "tags": []
   },
   "source": [
    "##  Analyze documents with Amazon Textract and split them in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "304a7705-a286-40cf-a9c0-18d6b6901313",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded s3://rag-langchain-demo/1026-ednalyn-de-dios-machine-learning-engineer-data-scientist-manager-readable-2023.pdf, 2 pages, 20 chunks\n",
      "Loaded s3://rag-langchain-demo/1101-ednalyn-de-dios-machine-learning-engineer-data-scientist-manager-readable-2023.pdf, 2 pages, 21 chunks\n",
      "Loaded s3://rag-langchain-demo/925-ednalyn-de-dios-machine-learning-engineer-data-scientist-manager-readable-2023.pdf, 2 pages, 20 chunks\n",
      "CPU times: user 772 ms, sys: 18.5 ms, total: 791 ms\n",
      "Wall time: 28.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "textract_client = boto3.client('textract')\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=256, chunk_overlap=0)\n",
    "\n",
    "all_chunks = []\n",
    "\n",
    "for uri in uris:\n",
    "    loader = AmazonTextractPDFLoader(uri, client=textract_client)\n",
    "    document = loader.load()\n",
    "    chunks = splitter.split_documents(document)\n",
    "    all_chunks += chunks\n",
    "    print(f\"Loaded {uri}, {len(document)} pages, {len(chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b8e1da-96f8-41a1-a1e0-4ef12c0ebd79",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Embed document chunks and store them in FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e96417dd-246f-4112-90ec-fb260b055423",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define embedding model\n",
    "# See https://huggingface.co/spaces/mteb/leaderboard\n",
    "\n",
    "embedding_model_id = \"BAAI/bge-small-en-v1.5\"\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=embedding_model_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cd334dd-93a8-437b-97ec-707b725661a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.39 s, sys: 136 ms, total: 2.52 s\n",
      "Wall time: 2.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Embed chunks\n",
    "embeddings_db = FAISS.from_documents(all_chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2dc88480-d6fa-44fa-9037-5ec888e437fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save database\n",
    "embeddings_db.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747c0ffd-ade6-46fc-a787-9feaeddbe921",
   "metadata": {},
   "source": [
    "## Shortcut : load existing embedding database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0a7f46b-fb1b-4d71-b862-d2526d8d8fa9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings_db = FAISS.load_local(\"faiss_index\", embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19536306-ecf5-4cba-ba40-368217566d9e",
   "metadata": {},
   "source": [
    "## Configure RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e280bd2-227a-4f2c-b8c4-2d1c4aac484c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever = embeddings_db.as_retriever(search_kwargs={\"k\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c56c461-de28-4669-941d-6af80f21d8d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define prompt template\n",
    "prompt_template = \"\"\"\n",
    "As a helpful human resource specialist, please answer the question.\n",
    "Don't invent facts. If you can't provide a factual answer, say you don't know what the answer is.\n",
    "\n",
    "question: {question}\n",
    "\n",
    "context: {context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1087fcb4-3226-4a8d-8ae6-9c408f6129c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever, \n",
    "    chain_type_kwargs = {\"prompt\": prompt})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b6ede5-fdf1-4e51-891e-93a02af0469e",
   "metadata": {},
   "source": [
    "## Ask our question again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cda6aaa3-0c16-4279-aea6-a57e30bde7c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the information provided, Ednalyn C. De Dios has over 10 years of management experience. However, I don't have access to her full career history or education, so I can't provide a specific number of years of experience.\n"
     ]
    }
   ],
   "source": [
    "question = \"How many years of experience does Ednalyn C. De Dios have?\"\n",
    "answer = chain.run({\"query\": question})\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a68704-eb54-4897-a2a4-d16e33e32bde",
   "metadata": {},
   "source": [
    "## Delete endpoint and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3fc952c1-b96d-4c61-b2ca-fa1062660286",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
